{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFCjcfHIs8D4"
      },
      "outputs": [],
      "source": [
        "!pip install -q pandas scikit-learn google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f8afa01"
      },
      "source": [
        "%ls -R"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()   # this will open a file picker\n"
      ],
      "metadata": {
        "id": "vtuHGVlSSkKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# .ZIP File Extraction & Datasets Loading"
      ],
      "metadata": {
        "id": "9gduKJrG6pYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"sentiment labelled sentences.zip\"   # file is in /content/\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"sentiment_labelled_sentences\")  # extract into this folder\n",
        "\n",
        "print(\"‚úÖ Extracted successfully!\")\n",
        "!ls sentiment_labelled_sentences\n"
      ],
      "metadata": {
        "id": "nmCyF1uvUalK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "amazon_df = pd.read_csv(\n",
        "    \"sentiment_labelled_sentences/sentiment labelled sentences/amazon_cells_labelled.txt\",\n",
        "    delimiter=\"\\t\", header=None, names=[\"text\", \"label\"]\n",
        ")\n",
        "\n",
        "print(\"Amazon shape:\", amazon_df.shape)\n",
        "print(amazon_df.head())\n"
      ],
      "metadata": {
        "id": "fPRavJC0V1aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_df = pd.read_csv(\n",
        "    \"sentiment_labelled_sentences/sentiment labelled sentences/imdb_labelled.txt\",\n",
        "    delimiter=\"\\t\", header=None, names=[\"text\", \"label\"]\n",
        ")\n",
        "\n",
        "print(\"IMDb shape:\", imdb_df.shape)\n",
        "print(imdb_df.head())\n"
      ],
      "metadata": {
        "id": "AWD7Wq5dXP4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yelp_df = pd.read_csv(\n",
        "    \"sentiment_labelled_sentences/sentiment labelled sentences/yelp_labelled.txt\",\n",
        "    delimiter=\"\\t\", header=None, names=[\"text\", \"label\"]\n",
        ")\n",
        "\n",
        "print(\"Yelp shape:\", yelp_df.shape)\n",
        "print(yelp_df.head())\n"
      ],
      "metadata": {
        "id": "pXcVABqpXYKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step # 1:- The Classic ML Classifier"
      ],
      "metadata": {
        "id": "aSuOYpZq6YQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 1: Import Libraries\n",
        "# ===============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "M_2YXa7yYAkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 2: Load the datasets\n",
        "# (already extracted earlier)\n",
        "# ===============================\n",
        "amazon_df = pd.read_csv(\n",
        "    \"sentiment_labelled_sentences/sentiment labelled sentences/amazon_cells_labelled.txt\",\n",
        "    delimiter=\"\\t\", header=None, names=[\"text\", \"label\"]\n",
        ")\n",
        "\n",
        "imdb_df = pd.read_csv(\n",
        "    \"sentiment_labelled_sentences/sentiment labelled sentences/imdb_labelled.txt\",\n",
        "    delimiter=\"\\t\", header=None, names=[\"text\", \"label\"]\n",
        ")\n",
        "\n",
        "yelp_df = pd.read_csv(\n",
        "    \"sentiment_labelled_sentences/sentiment labelled sentences/yelp_labelled.txt\",\n",
        "    delimiter=\"\\t\", header=None, names=[\"text\", \"label\"]\n",
        ")\n",
        "\n",
        "# Combine into one dataset\n",
        "df = pd.concat([amazon_df, imdb_df, yelp_df], ignore_index=True)\n",
        "print(\"‚úÖ Dataset loaded. Shape:\", df.shape)"
      ],
      "metadata": {
        "id": "RJVd9nDKZv5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 3: Preprocess text\n",
        "# ===============================\n",
        "def clean_text(text):\n",
        "    text = text.lower()                           # lowercase\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)    # remove URLs\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)          # keep only letters\n",
        "    tokens = text.split()                         # tokenize\n",
        "    tokens = [t for t in tokens if t not in stop_words]  # remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
        "print(\"‚úÖ Text preprocessing complete.\")"
      ],
      "metadata": {
        "id": "5RE5HbuRaA-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 4: Vectorization (TF-IDF)\n",
        "# ===============================\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df[\"clean_text\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Data vectorized and split. Train size:\", X_train.shape, \" Test size:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "UUcf31jraNi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 5: Train Classic ML Models\n",
        "# ===============================\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"SVM\": LinearSVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = [acc, prec, rec, f1]\n",
        "\n",
        "    print(f\"\\nüìå {name} Results\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gBs6ws45abC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 6: Compare Models\n",
        "# ===============================\n",
        "results_df = pd.DataFrame(results, index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "print(\"\\n‚úÖ Model Comparison:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "yo7xN_sralhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step # 2:- The Modern LLM Analyzer"
      ],
      "metadata": {
        "id": "Skl0NTmI52nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 1: Install Gemini SDK\n",
        "# ===============================\n",
        "!pip install -q google-generativeai\n"
      ],
      "metadata": {
        "id": "nLcgygMxbbI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 2: Import Libraries\n",
        "# ===============================\n",
        "import os\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "UnkEqbgWfd9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "7ycj6l-Gf_Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSVLyQVpf1aY"
      },
      "source": [
        "# ===============================\n",
        "# üìå Step 3: Configure Gemini API\n",
        "# ===============================\n",
        "# Use the environment variable name exactly as given in project PDF\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Retrieve securely from Colab Secrets\n",
        "api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"‚ùå GOOGLE_API_KEY not found in Colab secrets\")\n",
        "\n",
        "# Configure Gemini client\n",
        "genai.configure(api_key=api_key)\n",
        "print(\"‚úÖ Gemini API configured successfully (key loaded securely)\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 4: Define Sentiment Function\n",
        "# ===============================\n",
        "def gemini_sentiment(text):\n",
        "    \"\"\"\n",
        "    Ask Gemini to classify sentiment.\n",
        "    Output: 1 (Positive), 0 (Negative)\n",
        "    \"\"\"\n",
        "    prompt = f\"Classify the sentiment of this review as Positive (1) or Negative (0):\\n\\n{text}\"\n",
        "    response = gemini_model.generate_content(prompt)\n",
        "    prediction = response.text.strip()\n",
        "\n",
        "    # Normalize Gemini‚Äôs response to numeric label\n",
        "    if \"1\" in prediction.lower() or \"positive\" in prediction.lower():\n",
        "        return 1\n",
        "    elif \"0\" in prediction.lower() or \"negative\" in prediction.lower():\n",
        "        return 0\n",
        "    else:\n",
        "        return -1  # fallback for ambiguous cases"
      ],
      "metadata": {
        "id": "C-RImOAtg58K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dbd662a"
      },
      "source": [
        "# ===============================\n",
        "# üìå Step 4.1: Initialize Gemini Model\n",
        "# ===============================\n",
        "# Initialize the Gemini model you want to use\n",
        "# For example, 'gemini-pro'\n",
        "gemini_model = genai.GenerativeModel('models/gemini-1.5-flash-latest')\n",
        "\n",
        "print(\"‚úÖ Gemini model initialized.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 5: Run on Sample Dataset\n",
        "# ===============================\n",
        "# (df must already be defined from Classic ML section)\n",
        "# Reduce the sample size significantly to avoid quota issues\n",
        "\n",
        "# Load the datasets (already extracted earlier)\n",
        "import pandas as pd\n",
        "\n",
        "amazon_df = pd.read_csv(\n",
        "    \"sentiment_labelled_sentences/sentiment labelled sentences/amazon_cells_labelled.txt\",\n",
        "    delimiter=\"\\t\", header=None, names=[\"text\", \"label\"]\n",
        ")\n",
        "\n",
        "imdb_df = pd.read_csv(\n",
        "    \"sentiment_labelled_sentences/sentiment labelled sentences/imdb_labelled.txt\",\n",
        "    delimiter=\"\\t\", header=None, names=[\"text\", \"label\"]\n",
        ")\n",
        "\n",
        "yelp_df = pd.read_csv(\n",
        "    \"sentiment_labelled_sentences/sentiment labelled sentences/yelp_labelled.txt\",\n",
        "    delimiter=\"\\t\", header=None, names=[\"text\", \"label\"]\n",
        ")\n",
        "\n",
        "# Combine into one dataset\n",
        "df = pd.concat([amazon_df, imdb_df, yelp_df], ignore_index=True)\n",
        "print(\"‚úÖ Dataset loaded. Shape:\", df.shape)\n",
        "\n",
        "sample_df = df.sample(3, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Apply Gemini sentiment analysis\n",
        "sample_df[\"gemini_pred\"] = sample_df[\"text\"].apply(gemini_sentiment)\n",
        "\n",
        "print(sample_df[[\"text\", \"label\", \"gemini_pred\"]])"
      ],
      "metadata": {
        "id": "dMtYPs0Uh_VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìå Step 6: Evaluate Performance\n",
        "# ===============================\n",
        "y_true = sample_df[\"label\"]\n",
        "y_pred = sample_df[\"gemini_pred\"]\n",
        "\n",
        "print(\"\\n‚úÖ Gemini Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "1xbocAj4oIw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a3e275d"
      },
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}